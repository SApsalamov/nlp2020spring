{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab 7 \n",
    "#### Rouge Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sultan/miniconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz \n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "from ipywidgets import interact, interact_manual\n",
    "import re\n",
    "__PATH__ = \"./data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/opt/tljh/user/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
    "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jupyter-\n",
      "[nltk_data]     alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter-\n",
      "[nltk_data]     alex/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(__PATH__,sep=\";\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>updatedDate</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>metaData</th>\n",
       "      <th>downloadLink</th>\n",
       "      <th>filePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1407.6950v1</td>\n",
       "      <td>2014-07-24T16:56:39Z</td>\n",
       "      <td>2014-07-24T16:56:39Z</td>\n",
       "      <td>How,whenAndHowMuchACardDeckIsWellShuffled.pdf</td>\n",
       "      <td>The Thesis Consider The Mixing Of Few  3 4  ...</td>\n",
       "      <td>Benjamin Isac Fargion</td>\n",
       "      <td>cs.DM</td>\n",
       "      <td>Italian Thesis In Engeenering Computer, 26 Feb...</td>\n",
       "      <td>http://arxiv.org/pdf/1407.6950v1.pdf</td>\n",
       "      <td>./files/How,whenAndHowMuchACardDeckIsWellShuff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/0907.0618v1</td>\n",
       "      <td>2009-07-03T12:35:10Z</td>\n",
       "      <td>2009-07-03T12:35:10Z</td>\n",
       "      <td>QuantumIsometryGroups.pdf</td>\n",
       "      <td>This Thesis Contains The Formulation And Com...</td>\n",
       "      <td>Jyotishman Bhowmick</td>\n",
       "      <td>math.OA</td>\n",
       "      <td>Thesis</td>\n",
       "      <td>http://arxiv.org/pdf/0907.0618v1.pdf</td>\n",
       "      <td>./files/QuantumIsometryGroups.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1806.09601v2</td>\n",
       "      <td>2018-07-14T17:06:27Z</td>\n",
       "      <td>2018-06-25T17:55:59Z</td>\n",
       "      <td>ComputationAndBoundingOfFolkmanNumbers.pdf</td>\n",
       "      <td>Phd Thesis Under The Supervision Of Professo...</td>\n",
       "      <td>Aleksandar Bikov</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>PhD Thesis</td>\n",
       "      <td>http://arxiv.org/pdf/1806.09601v2.pdf</td>\n",
       "      <td>./files/ComputationAndBoundingOfFolkmanNumbers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/1905.03014v1</td>\n",
       "      <td>2019-05-08T11:47:34Z</td>\n",
       "      <td>2019-05-08T11:47:34Z</td>\n",
       "      <td>OnChurch'sThesisInCubicalAssemblies.pdf</td>\n",
       "      <td>We Show That Church's Thesis, The Axiom Stat...</td>\n",
       "      <td>Andrew Swan, Taichi Uemura,</td>\n",
       "      <td>math.LO</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/1905.03014v1.pdf</td>\n",
       "      <td>./files/OnChurch'sThesisInCubicalAssemblies.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1901.04911v1</td>\n",
       "      <td>2019-01-15T16:24:07Z</td>\n",
       "      <td>2019-01-15T16:24:07Z</td>\n",
       "      <td>UnconstrainedChurchTuringThesisCannotPossiblyB...</td>\n",
       "      <td>The Church Turing Thesis Asserts That If A P...</td>\n",
       "      <td>Yuri Gurevich</td>\n",
       "      <td>cs.LO</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/1901.04911v1.pdf</td>\n",
       "      <td>./files/UnconstrainedChurchTuringThesisCannotP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>http://arxiv.org/abs/0709.0497v1</td>\n",
       "      <td>2007-09-04T18:40:50Z</td>\n",
       "      <td>2007-09-04T18:40:50Z</td>\n",
       "      <td>HardSpectatorInteractionsInBToPiPiAtOrderAlpha...</td>\n",
       "      <td>In The Present Thesis I Discuss The Hard Spe...</td>\n",
       "      <td>Volker Pilipp</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>PhD thesis</td>\n",
       "      <td>http://arxiv.org/pdf/0709.0497v1.pdf</td>\n",
       "      <td>./files/HardSpectatorInteractionsInBToPiPiAtOr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>http://arxiv.org/abs/0709.2936v1</td>\n",
       "      <td>2007-09-18T23:56:17Z</td>\n",
       "      <td>2007-09-18T23:56:17Z</td>\n",
       "      <td>BayesianClassificationAndRegressionWithHighDim...</td>\n",
       "      <td>This Thesis Responds To The Challenges Of Us...</td>\n",
       "      <td>Longhai Li</td>\n",
       "      <td>stat.ML</td>\n",
       "      <td>PhD Thesis Submitted to University of Toronto,...</td>\n",
       "      <td>http://arxiv.org/pdf/0709.2936v1.pdf</td>\n",
       "      <td>./files/BayesianClassificationAndRegressionWit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>http://arxiv.org/abs/0710.1790v1</td>\n",
       "      <td>2007-10-09T15:20:08Z</td>\n",
       "      <td>2007-10-09T15:20:08Z</td>\n",
       "      <td>StaticAndDynamicPropertiesOfHadronicSystemsWit...</td>\n",
       "      <td>This Thesis Has Been Devoted To The Study Of...</td>\n",
       "      <td>J. M. Verde-Velasco</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>PhD thesis, Supervisors: E. Hernandez, J. Niev...</td>\n",
       "      <td>http://arxiv.org/pdf/0710.1790v1.pdf</td>\n",
       "      <td>./files/StaticAndDynamicPropertiesOfHadronicSy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>http://arxiv.org/abs/0711.0873v2</td>\n",
       "      <td>2007-11-11T19:21:04Z</td>\n",
       "      <td>2007-11-06T14:13:50Z</td>\n",
       "      <td>AConformalApproachToNumericalCalculationsOfAsy...</td>\n",
       "      <td>This Thesis Is Concerned With The Developmen...</td>\n",
       "      <td>Anıl Zenginoğlu</td>\n",
       "      <td>gr-qc</td>\n",
       "      <td>PhD thesis, Max-Planck Institute for Gravitati...</td>\n",
       "      <td>http://arxiv.org/pdf/0711.0873v2.pdf</td>\n",
       "      <td>./files/AConformalApproachToNumericalCalculati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>http://arxiv.org/abs/0801.2858v1</td>\n",
       "      <td>2008-01-18T11:50:32Z</td>\n",
       "      <td>2008-01-18T11:50:32Z</td>\n",
       "      <td>TheoreticalAnalysisOfOptimizationProblemsSomeP...</td>\n",
       "      <td>This Thesis Is Divided In Two Parts. The Fir...</td>\n",
       "      <td>Fabrizio Altarelli</td>\n",
       "      <td>cond-mat.stat-mech</td>\n",
       "      <td>Ph.D. thesis, 132 pages</td>\n",
       "      <td>http://arxiv.org/pdf/0801.2858v1.pdf</td>\n",
       "      <td>./files/TheoreticalAnalysisOfOptimizationProbl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id           updatedDate  \\\n",
       "0     http://arxiv.org/abs/1407.6950v1  2014-07-24T16:56:39Z   \n",
       "1     http://arxiv.org/abs/0907.0618v1  2009-07-03T12:35:10Z   \n",
       "2    http://arxiv.org/abs/1806.09601v2  2018-07-14T17:06:27Z   \n",
       "3    http://arxiv.org/abs/1905.03014v1  2019-05-08T11:47:34Z   \n",
       "4    http://arxiv.org/abs/1901.04911v1  2019-01-15T16:24:07Z   \n",
       "..                                 ...                   ...   \n",
       "991   http://arxiv.org/abs/0709.0497v1  2007-09-04T18:40:50Z   \n",
       "992   http://arxiv.org/abs/0709.2936v1  2007-09-18T23:56:17Z   \n",
       "993   http://arxiv.org/abs/0710.1790v1  2007-10-09T15:20:08Z   \n",
       "994   http://arxiv.org/abs/0711.0873v2  2007-11-11T19:21:04Z   \n",
       "995   http://arxiv.org/abs/0801.2858v1  2008-01-18T11:50:32Z   \n",
       "\n",
       "            publishedDate                                              title  \\\n",
       "0    2014-07-24T16:56:39Z      How,whenAndHowMuchACardDeckIsWellShuffled.pdf   \n",
       "1    2009-07-03T12:35:10Z                          QuantumIsometryGroups.pdf   \n",
       "2    2018-06-25T17:55:59Z         ComputationAndBoundingOfFolkmanNumbers.pdf   \n",
       "3    2019-05-08T11:47:34Z            OnChurch'sThesisInCubicalAssemblies.pdf   \n",
       "4    2019-01-15T16:24:07Z  UnconstrainedChurchTuringThesisCannotPossiblyB...   \n",
       "..                    ...                                                ...   \n",
       "991  2007-09-04T18:40:50Z  HardSpectatorInteractionsInBToPiPiAtOrderAlpha...   \n",
       "992  2007-09-18T23:56:17Z  BayesianClassificationAndRegressionWithHighDim...   \n",
       "993  2007-10-09T15:20:08Z  StaticAndDynamicPropertiesOfHadronicSystemsWit...   \n",
       "994  2007-11-06T14:13:50Z  AConformalApproachToNumericalCalculationsOfAsy...   \n",
       "995  2008-01-18T11:50:32Z  TheoreticalAnalysisOfOptimizationProblemsSomeP...   \n",
       "\n",
       "                                               summary  \\\n",
       "0      The Thesis Consider The Mixing Of Few  3 4  ...   \n",
       "1      This Thesis Contains The Formulation And Com...   \n",
       "2      Phd Thesis Under The Supervision Of Professo...   \n",
       "3      We Show That Church's Thesis, The Axiom Stat...   \n",
       "4      The Church Turing Thesis Asserts That If A P...   \n",
       "..                                                 ...   \n",
       "991    In The Present Thesis I Discuss The Hard Spe...   \n",
       "992    This Thesis Responds To The Challenges Of Us...   \n",
       "993    This Thesis Has Been Devoted To The Study Of...   \n",
       "994    This Thesis Is Concerned With The Developmen...   \n",
       "995    This Thesis Is Divided In Two Parts. The Fir...   \n",
       "\n",
       "                          authors            category  \\\n",
       "0           Benjamin Isac Fargion               cs.DM   \n",
       "1             Jyotishman Bhowmick             math.OA   \n",
       "2                Aleksandar Bikov             math.CO   \n",
       "3    Andrew Swan, Taichi Uemura,              math.LO   \n",
       "4                   Yuri Gurevich               cs.LO   \n",
       "..                            ...                 ...   \n",
       "991                 Volker Pilipp              hep-ph   \n",
       "992                    Longhai Li             stat.ML   \n",
       "993           J. M. Verde-Velasco              hep-ph   \n",
       "994               Anıl Zenginoğlu               gr-qc   \n",
       "995            Fabrizio Altarelli  cond-mat.stat-mech   \n",
       "\n",
       "                                              metaData  \\\n",
       "0    Italian Thesis In Engeenering Computer, 26 Feb...   \n",
       "1                                               Thesis   \n",
       "2                                           PhD Thesis   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "..                                                 ...   \n",
       "991                                         PhD thesis   \n",
       "992  PhD Thesis Submitted to University of Toronto,...   \n",
       "993  PhD thesis, Supervisors: E. Hernandez, J. Niev...   \n",
       "994  PhD thesis, Max-Planck Institute for Gravitati...   \n",
       "995                            Ph.D. thesis, 132 pages   \n",
       "\n",
       "                              downloadLink  \\\n",
       "0     http://arxiv.org/pdf/1407.6950v1.pdf   \n",
       "1     http://arxiv.org/pdf/0907.0618v1.pdf   \n",
       "2    http://arxiv.org/pdf/1806.09601v2.pdf   \n",
       "3    http://arxiv.org/pdf/1905.03014v1.pdf   \n",
       "4    http://arxiv.org/pdf/1901.04911v1.pdf   \n",
       "..                                     ...   \n",
       "991   http://arxiv.org/pdf/0709.0497v1.pdf   \n",
       "992   http://arxiv.org/pdf/0709.2936v1.pdf   \n",
       "993   http://arxiv.org/pdf/0710.1790v1.pdf   \n",
       "994   http://arxiv.org/pdf/0711.0873v2.pdf   \n",
       "995   http://arxiv.org/pdf/0801.2858v1.pdf   \n",
       "\n",
       "                                              filePath  \n",
       "0    ./files/How,whenAndHowMuchACardDeckIsWellShuff...  \n",
       "1                    ./files/QuantumIsometryGroups.pdf  \n",
       "2    ./files/ComputationAndBoundingOfFolkmanNumbers...  \n",
       "3      ./files/OnChurch'sThesisInCubicalAssemblies.pdf  \n",
       "4    ./files/UnconstrainedChurchTuringThesisCannotP...  \n",
       "..                                                 ...  \n",
       "991  ./files/HardSpectatorInteractionsInBToPiPiAtOr...  \n",
       "992  ./files/BayesianClassificationAndRegressionWit...  \n",
       "993  ./files/StaticAndDynamicPropertiesOfHadronicSy...  \n",
       "994  ./files/AConformalApproachToNumericalCalculati...  \n",
       "995  ./files/TheoreticalAnalysisOfOptimizationProbl...  \n",
       "\n",
       "[996 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the title to list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(df['title'].apply(\n",
    "    lambda t : \n",
    "        tuple(\n",
    "            filter(lambda e:not e in stopwords.words('english'),\n",
    "                map(lambda e:e.lower(),\n",
    "                       re.findall('([A-Z]{1}[a-z]+)',t.replace('.pdf','')))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('much', 'card', 'deck', 'well', 'shuffled'),\n",
       " ('quantum', 'isometry', 'groups'),\n",
       " ('computation', 'bounding', 'folkman', 'numbers'),\n",
       " ('church', 'thesis', 'cubical', 'assemblies'),\n",
       " ('unconstrained', 'church', 'turing', 'thesis', 'cannot', 'possibly', 'true'),\n",
       " ('algebraic',\n",
       "  'relaxations',\n",
       "  'hardness',\n",
       "  'results',\n",
       "  'polynomial',\n",
       "  'optimization',\n",
       "  'lyapunov',\n",
       "  'analysis'),\n",
       " ('resolving',\n",
       "  'complexity',\n",
       "  'fundamental',\n",
       "  'problems',\n",
       "  'computational',\n",
       "  'social',\n",
       "  'choice'),\n",
       " ('pa',\n",
       "  'instantiationally',\n",
       "  'complete',\n",
       "  'algorithmically',\n",
       "  'incomplete',\n",
       "  'alternative',\n",
       "  'interpretation',\n",
       "  'goedelian',\n",
       "  'incompleteness',\n",
       "  'church',\n",
       "  'thesis',\n",
       "  'links',\n",
       "  'formal',\n",
       "  'logic',\n",
       "  'computability'),\n",
       " ('numerical',\n",
       "  'modeling',\n",
       "  'fluid',\n",
       "  'flow',\n",
       "  'porous',\n",
       "  'media',\n",
       "  'modelowanie',\n",
       "  'numeryczne',\n",
       "  'transportu',\n",
       "  'plynow',\n",
       "  'przez',\n",
       "  'osrodki',\n",
       "  'porowate'),\n",
       " ('threebranes', 'theory'),\n",
       " ('spin',\n",
       "  'torque',\n",
       "  'nano',\n",
       "  'oscillators',\n",
       "  'memristors',\n",
       "  'multi',\n",
       "  'functional',\n",
       "  'nanodevices',\n",
       "  'advanced',\n",
       "  'computing'),\n",
       " ('effectuses', 'categorical', 'quantum', 'foundations'),\n",
       " ('hypercomputation',\n",
       "  'towards',\n",
       "  'extension',\n",
       "  'classical',\n",
       "  'notion',\n",
       "  'computability'),\n",
       " ('estimation', 'use', 'statistical', 'modelling', 'information', 'retrieval'),\n",
       " ('combinatorial', 'koszul', 'homology', 'computations', 'applications'),\n",
       " ('effective', 'banach', 'spaces'),\n",
       " ('computing',),\n",
       " ('first', 'principles', 'study', 'intein', 'reaction', 'mechanisms'),\n",
       " ('guarding', 'searching', 'polyhedra'),\n",
       " ('adaptation', 'self', 'organization', 'evolutionary', 'algorithms')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for title in titles[:20]:\n",
    "    synsets = {}\n",
    "    for word in title:\n",
    "        synsets[word]=[synset for synset in wn.synsets(word)]\n",
    "    res[title] = synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('much',\n",
       "  'card',\n",
       "  'deck',\n",
       "  'well',\n",
       "  'shuffled'): {'much': [Synset('much.n.01'),\n",
       "   Synset('much.a.01'),\n",
       "   Synset('much.r.01'),\n",
       "   Synset('much.r.02'),\n",
       "   Synset('a_lot.r.01'),\n",
       "   Synset('much.r.04'),\n",
       "   Synset('much.r.05')], 'card': [Synset('card.n.01'),\n",
       "   Synset('card.n.02'),\n",
       "   Synset('card.n.03'),\n",
       "   Synset('card.n.04'),\n",
       "   Synset('wag.n.01'),\n",
       "   Synset('poster.n.01'),\n",
       "   Synset('calling_card.n.02'),\n",
       "   Synset('card.n.08'),\n",
       "   Synset('menu.n.01'),\n",
       "   Synset('batting_order.n.01'),\n",
       "   Synset('circuit_board.n.01'),\n",
       "   Synset('tease.v.07'),\n",
       "   Synset('card.v.02')], 'deck': [Synset('deck.n.01'),\n",
       "   Synset('deck.n.02'),\n",
       "   Synset('pack_of_cards.n.01'),\n",
       "   Synset('deck.n.04'),\n",
       "   Synset('deck.v.01'),\n",
       "   Synset('deck.v.02'),\n",
       "   Synset('deck.v.03')], 'well': [Synset('well.n.01'),\n",
       "   Synset('well.n.02'),\n",
       "   Synset('well.n.03'),\n",
       "   Synset('well.n.04'),\n",
       "   Synset('well.n.05'),\n",
       "   Synset('well.v.01'),\n",
       "   Synset('well.a.01'),\n",
       "   Synset('good.s.13'),\n",
       "   Synset('well.s.03'),\n",
       "   Synset('well.r.01'),\n",
       "   Synset('well.r.02'),\n",
       "   Synset('well.r.03'),\n",
       "   Synset('well.r.04'),\n",
       "   Synset('well.r.05'),\n",
       "   Synset('well.r.06'),\n",
       "   Synset('well.r.07'),\n",
       "   Synset('well.r.08'),\n",
       "   Synset('well.r.09'),\n",
       "   Synset('well.r.10'),\n",
       "   Synset('well.r.11'),\n",
       "   Synset('well.r.12'),\n",
       "   Synset('well.r.13')], 'shuffled': [Synset('shuffle.v.01'),\n",
       "   Synset('shuffle.v.02'),\n",
       "   Synset('shuffle.v.03')]},\n",
       " ('quantum',\n",
       "  'isometry',\n",
       "  'groups'): {'quantum': [Synset('quantum.n.01'),\n",
       "   Synset('quantum.n.02')], 'isometry': [Synset('isometry.n.01'),\n",
       "   Synset('isometry.n.02'),\n",
       "   Synset('isometry.n.03'),\n",
       "   Synset('isometry.n.04')], 'groups': [Synset('group.n.01'),\n",
       "   Synset('group.n.02'),\n",
       "   Synset('group.n.03'),\n",
       "   Synset('group.v.01'),\n",
       "   Synset('group.v.02')]},\n",
       " ('computation',\n",
       "  'bounding',\n",
       "  'folkman',\n",
       "  'numbers'): {'computation': [Synset('calculation.n.01'),\n",
       "   Synset('calculation.n.02')], 'bounding': [Synset('jump.v.01'),\n",
       "   Synset('bound.v.02'),\n",
       "   Synset('restrict.v.03'),\n",
       "   Synset('bounce.v.01')], 'folkman': [], 'numbers': [Synset('numbers.n.01'),\n",
       "   Synset('numbers_pool.n.01'),\n",
       "   Synset('number.n.01'),\n",
       "   Synset('number.n.02'),\n",
       "   Synset('act.n.04'),\n",
       "   Synset('phone_number.n.01'),\n",
       "   Synset('numeral.n.01'),\n",
       "   Synset('issue.n.02'),\n",
       "   Synset('number.n.07'),\n",
       "   Synset('number.n.08'),\n",
       "   Synset('number.n.09'),\n",
       "   Synset('number.n.10'),\n",
       "   Synset('number.n.11'),\n",
       "   Synset('total.v.01'),\n",
       "   Synset('number.v.02'),\n",
       "   Synset('number.v.03'),\n",
       "   Synset('count.v.05'),\n",
       "   Synset('count.v.01'),\n",
       "   Synset('number.v.06')]},\n",
       " ('church',\n",
       "  'thesis',\n",
       "  'cubical',\n",
       "  'assemblies'): {'church': [Synset('church.n.01'),\n",
       "   Synset('church.n.02'),\n",
       "   Synset('church_service.n.01'),\n",
       "   Synset('church.n.04'),\n",
       "   Synset('church.v.01')], 'thesis': [Synset('thesis.n.01'),\n",
       "   Synset('dissertation.n.01')], 'cubical': [Synset('cubelike.s.01')], 'assemblies': [Synset('assembly.n.01'),\n",
       "   Synset('fabrication.n.04'),\n",
       "   Synset('forum.n.02'),\n",
       "   Synset('assembly.n.04'),\n",
       "   Synset('assembly.n.05'),\n",
       "   Synset('assembly.n.06')]},\n",
       " ('unconstrained',\n",
       "  'church',\n",
       "  'turing',\n",
       "  'thesis',\n",
       "  'cannot',\n",
       "  'possibly',\n",
       "  'true'): {'unconstrained': [Synset('unconstrained.s.01')],\n",
       "  'church': [Synset('church.n.01'),\n",
       "   Synset('church.n.02'),\n",
       "   Synset('church_service.n.01'),\n",
       "   Synset('church.n.04'),\n",
       "   Synset('church.v.01')],\n",
       "  'turing': [Synset('turing.n.01')],\n",
       "  'thesis': [Synset('thesis.n.01'), Synset('dissertation.n.01')],\n",
       "  'cannot': [],\n",
       "  'possibly': [Synset('possibly.r.01'), Synset('possibly.r.02')],\n",
       "  'true': [Synset('true.n.01'),\n",
       "   Synset('true.v.01'),\n",
       "   Synset('true.a.01'),\n",
       "   Synset('true.s.02'),\n",
       "   Synset('true.s.03'),\n",
       "   Synset('truthful.a.01'),\n",
       "   Synset('true.s.05'),\n",
       "   Synset('dependable.s.02'),\n",
       "   Synset('genuine.s.02'),\n",
       "   Synset('true.s.08'),\n",
       "   Synset('true.s.09'),\n",
       "   Synset('true.s.10'),\n",
       "   Synset('on-key.s.01'),\n",
       "   Synset('true.s.12'),\n",
       "   Synset('true.r.01')]},\n",
       " ('algebraic',\n",
       "  'relaxations',\n",
       "  'hardness',\n",
       "  'results',\n",
       "  'polynomial',\n",
       "  'optimization',\n",
       "  'lyapunov',\n",
       "  'analysis'): {'algebraic': [Synset('algebraic.a.01')],\n",
       "  'relaxations': [Synset('relaxation.n.01'),\n",
       "   Synset('relaxation.n.02'),\n",
       "   Synset('easiness.n.01'),\n",
       "   Synset('relaxation.n.04'),\n",
       "   Synset('rest.n.02'),\n",
       "   Synset('relaxation.n.06'),\n",
       "   Synset('liberalization.n.01')],\n",
       "  'hardness': [Synset('hardness.n.01'),\n",
       "   Synset('hardness.n.02'),\n",
       "   Synset('unfeelingness.n.01'),\n",
       "   Synset('hardness.n.04'),\n",
       "   Synset('severity.n.04')],\n",
       "  'results': [Synset('consequence.n.01'),\n",
       "   Synset('solution.n.02'),\n",
       "   Synset('result.n.03'),\n",
       "   Synset('resultant_role.n.01'),\n",
       "   Synset('result.v.01'),\n",
       "   Synset('leave.v.07'),\n",
       "   Synset('result.v.03')],\n",
       "  'polynomial': [Synset('polynomial.n.01'), Synset('polynomial.a.01')],\n",
       "  'optimization': [Synset('optimization.n.01')],\n",
       "  'lyapunov': [],\n",
       "  'analysis': [Synset('analysis.n.01'),\n",
       "   Synset('analysis.n.02'),\n",
       "   Synset('analysis.n.03'),\n",
       "   Synset('analysis.n.04'),\n",
       "   Synset('analysis.n.05'),\n",
       "   Synset('psychoanalysis.n.01')]},\n",
       " ('resolving',\n",
       "  'complexity',\n",
       "  'fundamental',\n",
       "  'problems',\n",
       "  'computational',\n",
       "  'social',\n",
       "  'choice'): {'resolving': [Synset('resolution.n.06'),\n",
       "   Synset('decide.v.02'),\n",
       "   Synset('conclude.v.03'),\n",
       "   Synset('purpose.v.02'),\n",
       "   Synset('answer.v.04'),\n",
       "   Synset('resolve.v.05'),\n",
       "   Synset('resolve.v.06'),\n",
       "   Synset('dissolve.v.02')],\n",
       "  'complexity': [Synset('complexity.n.01')],\n",
       "  'fundamental': [Synset('fundamental.n.01'),\n",
       "   Synset('fundamental.n.02'),\n",
       "   Synset('cardinal.s.01'),\n",
       "   Synset('fundamental.s.02'),\n",
       "   Synset('fundamental.s.03')],\n",
       "  'problems': [Synset('problem.n.01'),\n",
       "   Synset('problem.n.02'),\n",
       "   Synset('trouble.n.01')],\n",
       "  'computational': [Synset('computational.a.01')],\n",
       "  'social': [Synset('sociable.n.01'),\n",
       "   Synset('social.a.01'),\n",
       "   Synset('social.a.02'),\n",
       "   Synset('social.a.03'),\n",
       "   Synset('social.s.04'),\n",
       "   Synset('social.s.05'),\n",
       "   Synset('social.s.06')],\n",
       "  'choice': [Synset('choice.n.01'),\n",
       "   Synset('choice.n.02'),\n",
       "   Synset('option.n.02'),\n",
       "   Synset('choice.s.01'),\n",
       "   Synset('choice.s.02')]},\n",
       " ('pa',\n",
       "  'instantiationally',\n",
       "  'complete',\n",
       "  'algorithmically',\n",
       "  'incomplete',\n",
       "  'alternative',\n",
       "  'interpretation',\n",
       "  'goedelian',\n",
       "  'incompleteness',\n",
       "  'church',\n",
       "  'thesis',\n",
       "  'links',\n",
       "  'formal',\n",
       "  'logic',\n",
       "  'computability'): {'pa': [Synset('dad.n.01'),\n",
       "   Synset('protactinium.n.01'),\n",
       "   Synset('pascal.n.01'),\n",
       "   Synset('pennsylvania.n.01'),\n",
       "   Synset('public_address_system.n.01')],\n",
       "  'instantiationally': [],\n",
       "  'complete': [Synset('complete.v.01'),\n",
       "   Synset('complete.v.02'),\n",
       "   Synset('dispatch.v.02'),\n",
       "   Synset('complete.v.04'),\n",
       "   Synset('complete.v.05'),\n",
       "   Synset('complete.a.01'),\n",
       "   Synset('complete.s.02'),\n",
       "   Synset('accomplished.s.01'),\n",
       "   Synset('arrant.s.01'),\n",
       "   Synset('complete.s.05')],\n",
       "  'algorithmically': [],\n",
       "  'incomplete': [Synset('incomplete.a.01'), Synset('incomplete.s.02')],\n",
       "  'alternative': [Synset('option.n.02'),\n",
       "   Synset('alternate.s.02'),\n",
       "   Synset('alternative.s.02'),\n",
       "   Synset('alternative.s.03')],\n",
       "  'interpretation': [Synset('interpretation.n.01'),\n",
       "   Synset('rendition.n.04'),\n",
       "   Synset('interpretation.n.03'),\n",
       "   Synset('interpretation.n.04')],\n",
       "  'goedelian': [],\n",
       "  'incompleteness': [Synset('incompleteness.n.01')],\n",
       "  'church': [Synset('church.n.01'),\n",
       "   Synset('church.n.02'),\n",
       "   Synset('church_service.n.01'),\n",
       "   Synset('church.n.04'),\n",
       "   Synset('church.v.01')],\n",
       "  'thesis': [Synset('thesis.n.01'), Synset('dissertation.n.01')],\n",
       "  'links': [Synset('links.n.01'),\n",
       "   Synset('link.n.01'),\n",
       "   Synset('link.n.02'),\n",
       "   Synset('connection.n.02'),\n",
       "   Synset('connection.n.06'),\n",
       "   Synset('link.n.05'),\n",
       "   Synset('link.n.06'),\n",
       "   Synset('liaison.n.02'),\n",
       "   Synset('radio_link.n.01'),\n",
       "   Synset('link.n.09'),\n",
       "   Synset('associate.v.01'),\n",
       "   Synset('connect.v.01'),\n",
       "   Synset('connect.v.03'),\n",
       "   Synset('yoke.v.02')],\n",
       "  'formal': [Synset('ball.n.09'),\n",
       "   Synset('dinner_dress.n.01'),\n",
       "   Synset('formal.a.01'),\n",
       "   Synset('formal.s.02'),\n",
       "   Synset('formal.a.03'),\n",
       "   Synset('conventional.s.05'),\n",
       "   Synset('formal.s.05'),\n",
       "   Synset('courtly.s.01')],\n",
       "  'logic': [Synset('logic.n.01'),\n",
       "   Synset('logic.n.02'),\n",
       "   Synset('logic.n.03'),\n",
       "   Synset('logic.n.04'),\n",
       "   Synset('logic.n.05')],\n",
       "  'computability': []},\n",
       " ('numerical',\n",
       "  'modeling',\n",
       "  'fluid',\n",
       "  'flow',\n",
       "  'porous',\n",
       "  'media',\n",
       "  'modelowanie',\n",
       "  'numeryczne',\n",
       "  'transportu',\n",
       "  'plynow',\n",
       "  'przez',\n",
       "  'osrodki',\n",
       "  'porowate'): {'numerical': [Synset('numeric.s.02'),\n",
       "   Synset('numeral.a.01'),\n",
       "   Synset('numerical.a.03')],\n",
       "  'modeling': [Synset('mold.n.08'),\n",
       "   Synset('modeling.n.02'),\n",
       "   Synset('model.n.09'),\n",
       "   Synset('model.v.01'),\n",
       "   Synset('model.v.02'),\n",
       "   Synset('model.v.03'),\n",
       "   Synset('model.v.04'),\n",
       "   Synset('model.v.05'),\n",
       "   Synset('model.v.06')],\n",
       "  'fluid': [Synset('fluid.n.01'),\n",
       "   Synset('fluid.n.02'),\n",
       "   Synset('fluid.s.01'),\n",
       "   Synset('fluid.s.02'),\n",
       "   Synset('fluent.s.01'),\n",
       "   Synset('fluid.s.04'),\n",
       "   Synset('fluid.s.05')],\n",
       "  'flow': [Synset('flow.n.01'),\n",
       "   Synset('flow.n.02'),\n",
       "   Synset('flow.n.03'),\n",
       "   Synset('flow.n.04'),\n",
       "   Synset('stream.n.04'),\n",
       "   Synset('stream.n.02'),\n",
       "   Synset('menstruation.n.01'),\n",
       "   Synset('flow.v.01'),\n",
       "   Synset('run.v.06'),\n",
       "   Synset('flow.v.03'),\n",
       "   Synset('flow.v.04'),\n",
       "   Synset('hang.v.05'),\n",
       "   Synset('flow.v.06'),\n",
       "   Synset('menstruate.v.01')],\n",
       "  'porous': [Synset('porous.s.01'),\n",
       "   Synset('porous.a.02'),\n",
       "   Synset('holey.s.01')],\n",
       "  'media': [Synset('medium.n.01'),\n",
       "   Synset('medium.n.02'),\n",
       "   Synset('medium.n.03'),\n",
       "   Synset('culture_medium.n.01'),\n",
       "   Synset('medium.n.05'),\n",
       "   Synset('medium.n.06'),\n",
       "   Synset('medium.n.07'),\n",
       "   Synset('medium.n.08'),\n",
       "   Synset('medium.n.09'),\n",
       "   Synset('medium.n.10'),\n",
       "   Synset('metier.n.02')],\n",
       "  'modelowanie': [],\n",
       "  'numeryczne': [],\n",
       "  'transportu': [],\n",
       "  'plynow': [],\n",
       "  'przez': [],\n",
       "  'osrodki': [],\n",
       "  'porowate': []},\n",
       " ('threebranes', 'theory'): {'threebranes': [],\n",
       "  'theory': [Synset('theory.n.01'),\n",
       "   Synset('hypothesis.n.02'),\n",
       "   Synset('theory.n.03')]},\n",
       " ('spin',\n",
       "  'torque',\n",
       "  'nano',\n",
       "  'oscillators',\n",
       "  'memristors',\n",
       "  'multi',\n",
       "  'functional',\n",
       "  'nanodevices',\n",
       "  'advanced',\n",
       "  'computing'): {'spin': [Synset('spin.n.01'),\n",
       "   Synset('spin.n.02'),\n",
       "   Synset('spin.n.03'),\n",
       "   Synset('tailspin.n.02'),\n",
       "   Synset('spin.n.05'),\n",
       "   Synset('spin.v.01'),\n",
       "   Synset('spin.v.02'),\n",
       "   Synset('whirl.v.02'),\n",
       "   Synset('spin.v.04'),\n",
       "   Synset('spin.v.05'),\n",
       "   Synset('spin.v.06'),\n",
       "   Synset('spin.v.07'),\n",
       "   Synset('spin.v.08')],\n",
       "  'torque': [Synset('torsion.n.02')],\n",
       "  'nano': [],\n",
       "  'oscillators': [Synset('oscillator.n.01')],\n",
       "  'memristors': [],\n",
       "  'multi': [],\n",
       "  'functional': [Synset('functional.a.01'),\n",
       "   Synset('functional.a.02'),\n",
       "   Synset('functional.a.03'),\n",
       "   Synset('functional.s.04'),\n",
       "   Synset('functional.s.05'),\n",
       "   Synset('running.s.06')],\n",
       "  'nanodevices': [],\n",
       "  'advanced': [Synset('advance.v.01'),\n",
       "   Synset('advance.v.02'),\n",
       "   Synset('boost.v.04'),\n",
       "   Synset('promote.v.01'),\n",
       "   Synset('advance.v.05'),\n",
       "   Synset('gain.v.05'),\n",
       "   Synset('progress.v.01'),\n",
       "   Synset('advance.v.08'),\n",
       "   Synset('promote.v.02'),\n",
       "   Synset('advance.v.10'),\n",
       "   Synset('advance.v.11'),\n",
       "   Synset('advance.v.12'),\n",
       "   Synset('advanced.s.01'),\n",
       "   Synset('advanced.s.02'),\n",
       "   Synset('advanced.s.03'),\n",
       "   Synset('advanced.s.04'),\n",
       "   Synset('advanced.s.05'),\n",
       "   Synset('advanced.s.06'),\n",
       "   Synset('advanced.s.07'),\n",
       "   Synset('advance.s.02')],\n",
       "  'computing': [Synset('computer_science.n.01'),\n",
       "   Synset('calculation.n.01'),\n",
       "   Synset('calculate.v.01')]},\n",
       " ('effectuses', 'categorical', 'quantum', 'foundations'): {'effectuses': [],\n",
       "  'categorical': [Synset('categorical.a.01'), Synset('categoric.s.02')],\n",
       "  'quantum': [Synset('quantum.n.01'), Synset('quantum.n.02')],\n",
       "  'foundations': [Synset('foundation.n.01'),\n",
       "   Synset('foundation.n.02'),\n",
       "   Synset('foundation.n.03'),\n",
       "   Synset('foundation.n.04'),\n",
       "   Synset('basis.n.02'),\n",
       "   Synset('foundation_garment.n.01'),\n",
       "   Synset('initiation.n.02')]},\n",
       " ('hypercomputation',\n",
       "  'towards',\n",
       "  'extension',\n",
       "  'classical',\n",
       "  'notion',\n",
       "  'computability'): {'hypercomputation': [],\n",
       "  'towards': [],\n",
       "  'extension': [Synset('extension.n.01'),\n",
       "   Synset('extension.n.02'),\n",
       "   Synset('propagation.n.01'),\n",
       "   Synset('extension.n.04'),\n",
       "   Synset('extension.n.05'),\n",
       "   Synset('extension.n.06'),\n",
       "   Synset('reference.n.06'),\n",
       "   Synset('extension.n.08'),\n",
       "   Synset('extension.n.09'),\n",
       "   Synset('extension.n.10'),\n",
       "   Synset('elongation.n.02'),\n",
       "   Synset('annex.n.01')],\n",
       "  'classical': [Synset('classical_music.n.01'),\n",
       "   Synset('classical.a.01'),\n",
       "   Synset('authoritative.s.02'),\n",
       "   Synset('classical.a.03'),\n",
       "   Synset('classical.s.04'),\n",
       "   Synset('classical.s.05')],\n",
       "  'notion': [Synset('impression.n.01'),\n",
       "   Synset('notion.n.02'),\n",
       "   Synset('notion.n.03'),\n",
       "   Synset('notion.n.04')],\n",
       "  'computability': []},\n",
       " ('estimation',\n",
       "  'use',\n",
       "  'statistical',\n",
       "  'modelling',\n",
       "  'information',\n",
       "  'retrieval'): {'estimation': [Synset('appraisal.n.02'),\n",
       "   Synset('estimate.n.05'),\n",
       "   Synset('estimate.n.01'),\n",
       "   Synset('estimate.n.02')],\n",
       "  'use': [Synset('use.n.01'),\n",
       "   Synset('function.n.02'),\n",
       "   Synset('use.n.03'),\n",
       "   Synset('consumption.n.03'),\n",
       "   Synset('habit.n.02'),\n",
       "   Synset('manipulation.n.01'),\n",
       "   Synset('use.n.07'),\n",
       "   Synset('use.v.01'),\n",
       "   Synset('use.v.02'),\n",
       "   Synset('use.v.03'),\n",
       "   Synset('use.v.04'),\n",
       "   Synset('practice.v.04'),\n",
       "   Synset('use.v.06')],\n",
       "  'statistical': [Synset('statistical.a.01')],\n",
       "  'modelling': [Synset('modeling.n.02'),\n",
       "   Synset('model.n.09'),\n",
       "   Synset('model.v.01'),\n",
       "   Synset('model.v.02'),\n",
       "   Synset('model.v.03'),\n",
       "   Synset('model.v.04'),\n",
       "   Synset('model.v.05'),\n",
       "   Synset('model.v.06')],\n",
       "  'information': [Synset('information.n.01'),\n",
       "   Synset('information.n.02'),\n",
       "   Synset('information.n.03'),\n",
       "   Synset('data.n.01'),\n",
       "   Synset('information.n.05')],\n",
       "  'retrieval': [Synset('retrieval.n.01'),\n",
       "   Synset('retrieval.n.02'),\n",
       "   Synset('recovery.n.03')]},\n",
       " ('combinatorial',\n",
       "  'koszul',\n",
       "  'homology',\n",
       "  'computations',\n",
       "  'applications'): {'combinatorial': [Synset('combinative.s.02'),\n",
       "   Synset('combinatorial.s.02')], 'koszul': [], 'homology': [Synset('homology.n.01')], 'computations': [Synset('calculation.n.01'),\n",
       "   Synset('calculation.n.02')], 'applications': [Synset('application.n.01'),\n",
       "   Synset('application.n.02'),\n",
       "   Synset('application.n.03'),\n",
       "   Synset('application.n.04'),\n",
       "   Synset('lotion.n.02'),\n",
       "   Synset('application.n.06'),\n",
       "   Synset('application.n.07')]},\n",
       " ('effective',\n",
       "  'banach',\n",
       "  'spaces'): {'effective': [Synset('effective.a.01'),\n",
       "   Synset('effective.s.02'),\n",
       "   Synset('effective.s.03'),\n",
       "   Synset('effective.s.04'),\n",
       "   Synset('effective.s.05'),\n",
       "   Synset('effective.s.06')], 'banach': [], 'spaces': [Synset('space.n.01'),\n",
       "   Synset('space.n.02'),\n",
       "   Synset('space.n.03'),\n",
       "   Synset('outer_space.n.01'),\n",
       "   Synset('space.n.05'),\n",
       "   Synset('distance.n.05'),\n",
       "   Synset('space.n.07'),\n",
       "   Synset('space.n.08'),\n",
       "   Synset('quad.n.03'),\n",
       "   Synset('space.v.01')]},\n",
       " ('computing',): {'computing': [Synset('computer_science.n.01'),\n",
       "   Synset('calculation.n.01'),\n",
       "   Synset('calculate.v.01')]},\n",
       " ('first',\n",
       "  'principles',\n",
       "  'study',\n",
       "  'intein',\n",
       "  'reaction',\n",
       "  'mechanisms'): {'first': [Synset('first.n.01'),\n",
       "   Synset('first.n.02'),\n",
       "   Synset('beginning.n.02'),\n",
       "   Synset('first_base.n.02'),\n",
       "   Synset('first.n.05'),\n",
       "   Synset('first_gear.n.01'),\n",
       "   Synset('first.a.01'),\n",
       "   Synset('first.s.02'),\n",
       "   Synset('inaugural.s.02'),\n",
       "   Synset('beginning.s.01'),\n",
       "   Synset('first.s.05'),\n",
       "   Synset('first.a.06'),\n",
       "   Synset('first.r.01'),\n",
       "   Synset('first.r.02'),\n",
       "   Synset('first.r.03'),\n",
       "   Synset('foremost.r.01')], 'principles': [Synset('principle.n.01'),\n",
       "   Synset('principle.n.02'),\n",
       "   Synset('principle.n.03'),\n",
       "   Synset('principle.n.04'),\n",
       "   Synset('principle.n.05'),\n",
       "   Synset('rationale.n.01')], 'study': [Synset('survey.n.01'),\n",
       "   Synset('study.n.02'),\n",
       "   Synset('report.n.01'),\n",
       "   Synset('study.n.04'),\n",
       "   Synset('study.n.05'),\n",
       "   Synset('discipline.n.01'),\n",
       "   Synset('sketch.n.01'),\n",
       "   Synset('cogitation.n.02'),\n",
       "   Synset('study.n.09'),\n",
       "   Synset('study.n.10'),\n",
       "   Synset('analyze.v.01'),\n",
       "   Synset('study.v.02'),\n",
       "   Synset('study.v.03'),\n",
       "   Synset('learn.v.04'),\n",
       "   Synset('study.v.05'),\n",
       "   Synset('study.v.06')], 'intein': [], 'reaction': [Synset('chemical_reaction.n.01'),\n",
       "   Synset('reaction.n.02'),\n",
       "   Synset('reaction.n.03'),\n",
       "   Synset('reaction.n.04'),\n",
       "   Synset('reaction.n.05'),\n",
       "   Synset('reaction.n.06'),\n",
       "   Synset('reaction.n.07')], 'mechanisms': [Synset('mechanism.n.01'),\n",
       "   Synset('mechanism.n.02'),\n",
       "   Synset('mechanism.n.03'),\n",
       "   Synset('mechanism.n.04'),\n",
       "   Synset('mechanism.n.05')]},\n",
       " ('guarding',\n",
       "  'searching',\n",
       "  'polyhedra'): {'guarding': [Synset('guard.v.01'),\n",
       "   Synset('guard.v.02'),\n",
       "   Synset('defend.v.03'),\n",
       "   Synset('guard.v.04')], 'searching': [Synset('search.v.01'),\n",
       "   Synset('search.v.02'),\n",
       "   Synset('research.v.02'),\n",
       "   Synset('search.v.04'),\n",
       "   Synset('inquisitory.s.01'),\n",
       "   Synset('searching.s.02'),\n",
       "   Synset('searching.s.03')], 'polyhedra': [Synset('polyhedron.n.01')]},\n",
       " ('adaptation',\n",
       "  'self',\n",
       "  'organization',\n",
       "  'evolutionary',\n",
       "  'algorithms'): {'adaptation': [Synset('adaptation.n.01'),\n",
       "   Synset('adaptation.n.02'),\n",
       "   Synset('adaptation.n.03')], 'self': [Synset('self.n.01'),\n",
       "   Synset('self.n.02'),\n",
       "   Synset('self.a.01')], 'organization': [Synset('organization.n.01'),\n",
       "   Synset('arrangement.n.03'),\n",
       "   Synset('administration.n.02'),\n",
       "   Synset('organization.n.04'),\n",
       "   Synset('organization.n.05'),\n",
       "   Synset('organization.n.06'),\n",
       "   Synset('constitution.n.02')], 'evolutionary': [Synset('evolutionary.a.01')], 'algorithms': [Synset('algorithm.n.01')]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(('much', 'card', 'deck', 'well', 'shuffled'), {'much': [Synset('much.n.01'), Synset('much.a.01'), Synset('much.r.01'), Synset('much.r.02'), Synset('a_lot.r.01'), Synset('much.r.04'), Synset('much.r.05')], 'card': [Synset('card.n.01'), Synset('card.n.02'), Synset('card.n.03'), Synset('card.n.04'), Synset('wag.n.01'), Synset('poster.n.01'), Synset('calling_card.n.02'), Synset('card.n.08'), Synset('menu.n.01'), Synset('batting_order.n.01'), Synset('circuit_board.n.01'), Synset('tease.v.07'), Synset('card.v.02')], 'deck': [Synset('deck.n.01'), Synset('deck.n.02'), Synset('pack_of_cards.n.01'), Synset('deck.n.04'), Synset('deck.v.01'), Synset('deck.v.02'), Synset('deck.v.03')], 'well': [Synset('well.n.01'), Synset('well.n.02'), Synset('well.n.03'), Synset('well.n.04'), Synset('well.n.05'), Synset('well.v.01'), Synset('well.a.01'), Synset('good.s.13'), Synset('well.s.03'), Synset('well.r.01'), Synset('well.r.02'), Synset('well.r.03'), Synset('well.r.04'), Synset('well.r.05'), Synset('well.r.06'), Synset('well.r.07'), Synset('well.r.08'), Synset('well.r.09'), Synset('well.r.10'), Synset('well.r.11'), Synset('well.r.12'), Synset('well.r.13')], 'shuffled': [Synset('shuffle.v.01'), Synset('shuffle.v.02'), Synset('shuffle.v.03')]})\n"
     ]
    }
   ],
   "source": [
    "reslist = list(res.items())\n",
    "print(len(reslist))\n",
    "print(reslist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('much.n.01'), Synset('much.a.01'), Synset('much.r.01'), Synset('much.r.02'), Synset('a_lot.r.01'), Synset('much.r.04'), Synset('much.r.05')]\n"
     ]
    }
   ],
   "source": [
    "print(reslist[0][1]['much'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('much', 'card', 'deck', 'well', 'shuffled')\n"
     ]
    }
   ],
   "source": [
    "print(reslist[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'card', 'deck', 'much', 'shuffled', 'well'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resset = set(reslist[0][0])\n",
    "resset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> shuffled\n",
      "<class 'str'> much\n",
      "<class 'str'> well\n",
      "<class 'str'> card\n",
      "<class 'str'> deck\n"
     ]
    }
   ],
   "source": [
    "for word in resset:\n",
    "    print(type(word), word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('shuffle.v.01'), Synset('shuffle.v.02'), Synset('shuffle.v.03')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shufsynset = wn.synsets('shuffled')\n",
    "shufsynset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('walk.v.01')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset = wn.synsets('shuffled')[0]\n",
    "synset.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_classes(synset):\n",
    "    hyps = set()\n",
    "    while True:\n",
    "        try:\n",
    "            synset = synset.hypernyms()[-1]\n",
    "            hyps.add(synset)\n",
    "        except IndexError:\n",
    "            break\n",
    "    return hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('travel.v.01'), Synset('walk.v.01')}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parent_classes(shufsynset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypornyms_en(a):\n",
    "    hypornyms_en = set()\n",
    "    for word in a:\n",
    "        # find the hypernyms of the word\n",
    "        # word = wn.synset(word)\n",
    "        try:\n",
    "            word_synset0 = wn.synsets(word)[0]\n",
    "            hyps_buff = get_parent_classes(word_synset0)\n",
    "            for h in hyps_buff:\n",
    "                hypornyms_en.add(h)\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return hypornyms_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('abstraction.n.06'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('entity.n.01'),\n",
       " Synset('excavation.n.03'),\n",
       " Synset('horizontal_surface.n.01'),\n",
       " Synset('indefinite_quantity.n.01'),\n",
       " Synset('large_indefinite_quantity.n.01'),\n",
       " Synset('material.n.01'),\n",
       " Synset('measure.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('paper.n.01'),\n",
       " Synset('part.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('platform.n.01'),\n",
       " Synset('relation.n.01'),\n",
       " Synset('substance.n.01'),\n",
       " Synset('surface.n.01'),\n",
       " Synset('travel.v.01'),\n",
       " Synset('walk.v.01'),\n",
       " Synset('whole.n.02')}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_hypornyms_en(resset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1measure(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    # missed part\n",
    "    overlap = set()\n",
    "    overlap_hyp_cnt = 0\n",
    "    overlap = a.intersection(b)\n",
    "    overlap_hyp_cnt = len(overlap) \n",
    "    \n",
    "    recl = overlap_hyp_cnt/len(a)\n",
    "    prec = overlap_hyp_cnt/len(b)\n",
    "    \n",
    "    if len(overlap) == 0:\n",
    "        return 0, overlap\n",
    "    else:\n",
    "        return 2*recl*prec/(recl+prec), overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('much', 'card', 'deck', 'well', 'shuffled')\n",
      "('quantum', 'isometry', 'groups')\n"
     ]
    }
   ],
   "source": [
    "print(reslist[0][0])\n",
    "print(reslist[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "aset = set(reslist[0][0])\n",
    "bset = set(('much', 'card', 'deck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deck', 'much', 'card'}\n"
     ]
    }
   ],
   "source": [
    "print(aset.intersection(bset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'card', 'deck', 'much', 'shuffled', 'well'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = set(reslist[0][1])\n",
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, set())"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1measure(reslist[0][0], reslist[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'eng'\n",
    "\n",
    "    \n",
    "#def distance(a,b):\n",
    "    ### Put your code here\n",
    "    ### В переменной synsets помимо нормализованного заголовка хранятся синсеты для каждого токена из заголовка.\n",
    "    ### у синсетов есть гиперонимы про то как из брать здесь\n",
    "    ### Если у токенов заголовков есть общие гиперонимы тогда заголовки связаны несмотря на то что слова разные\n",
    "    \n",
    "    #return float((100-fuzz.ratio(a,b))/100)\n",
    "\n",
    "    \n",
    "def distance(a,b):\n",
    "    ### Put your code here\n",
    "    ### В переменной synsets помимо нормализованного заголовка хранятся синсеты для каждого токена из заголовка.\n",
    "    ### у синсетов есть гиперонимы про то как из брать здесь\n",
    "    ### Если у токенов заголовков есть общие гиперонимы тогда заголовки связаны несмотря на то что слова разные\n",
    "    \n",
    "    a = set(a) \n",
    "    b = set(b) \n",
    "    f1score, overlap = f1measure(a, b)\n",
    "    a = a - overlap\n",
    "    b = b - overlap\n",
    "    \n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 1.0 - f1score\n",
    "    \n",
    "    buff_a = {}\n",
    "    buff_b = {}\n",
    "    \n",
    "    if lang == 'eng':\n",
    "        buff_a = extract_hypornyms_en(a)\n",
    "        buff_b = extract_hypornyms_en(b)\n",
    "        \n",
    "    overlap_hyp_cnt = 0\n",
    "    \n",
    "    #for word in a:\n",
    "    #    for wordb in b:\n",
    "    #        if len(buff_a[word].intersection(buff_b[wordb])) > 0:\n",
    "    #            overlap_hyp_cnt += 1\n",
    "    \n",
    "    overlap = a.intersection(b)\n",
    "    overlap_hyp_cnt = len(overlap) \n",
    "    \n",
    "    recl_hyp = overlap_hyp_cnt/len(a)\n",
    "    prec_hyp = overlap_hyp_cnt/len(b)\n",
    "    f1score_hyp = 2*recl_hyp/(recl_hyp + prec_hyp) if overlap_hyp_cnt > 0 else 0\n",
    "    f1res = (2*f1score+f1score_hyp)/3\n",
    "    return (1.0 - f1res)\n",
    "\n",
    "buff = list(res.items())\n",
    "dist = np.zeros((len(buff),len(buff)))\n",
    "for lli,ll in enumerate(buff):\n",
    "    for rri,rr in enumerate(buff):\n",
    "        dist[lli,rri] = distance(ll[0], rr[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.80952381, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 0.        , 0.75757576,\n",
       "        1.        , 1.        , 0.85964912, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 0.75757576, 0.        ,\n",
       "        1.        , 1.        , 0.87878788, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 0.85964912, 0.87878788,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.93650794, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.81818182, 1.        , 1.        , 1.        ],\n",
       "       [1.        , 0.80952381, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.93650794, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.81818182, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('much', 'card', 'deck', 'well', 'shuffled')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buff[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top ten closest articles with fuzzy metrics of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2bb4bc1ce244f880685a52a4c97109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='ind', max=19), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(ind=(0,len(buff)-1,1))\n",
    "def h(ind=0):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(' '.join(buff[ind][0]))\n",
    "    pp.pprint([buff[i][0] for i in dist[ind][:].argsort()[1:11]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e2b863fe7141b7823a01eda8cdb5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='ind', max=19), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(ind=(0,len(buff)-1,1))\n",
    "def hypernyms(ind=0):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(' '.join(buff[ind][0]))\n",
    "    pp.pprint(buff[ind][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
